{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_ger-eng_questions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ueeUkE9Pvs91"
      },
      "source": [
        "# Neural Machine Translation\n",
        "\n",
        "- Translate a given sentence in one language to another desired language.\n",
        "\n",
        "#### In this notebook, we aim to build a model which can translate German sentences to English."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HphxvZ0fv_kr"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Dataset is taken from http://www.manythings.org/anki/.\n",
        "\n",
        "We are considering German – English deu-eng.zip file from the above mentioned website.\n",
        "\n",
        "In the above zip file there is a file with name **`deu.txt`** that contains **152,820** pairs of English to German phrases, one pair per line with a tab separating the phrases.\n",
        "\n",
        "\n",
        "For example,\n",
        "\n",
        "The first 5 lines in deu.txt are as given below.\n",
        "\n",
        "***\n",
        "```\n",
        "Hi.    Hallo!\n",
        "Hi.    Grüß Gott!\n",
        "Run!    Lauf!\n",
        "Wow!    Potzdonner!\n",
        "Wow!    Donnerwetter!\n",
        "```\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KzhjY_3MxlCT"
      },
      "source": [
        "## Problem\n",
        "\n",
        "### Given a sequence of words in German as input, predict the sequence of words in English."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "STq1sKSHywCQ"
      },
      "source": [
        "### 1. Prepare Data\n",
        "\n",
        "\n",
        "The preprocessing of the data involves:\n",
        "\n",
        "1. Removing punctuation marks from the data.\n",
        "\n",
        "2. Converting text corpus into lower case characters.\n",
        "\n",
        "3. Split into Train and Test sets.\n",
        "\n",
        "4. Shuffling the sentences.\n",
        "\n",
        "\n",
        "\n",
        "The above tasks are done  and full dataset is given as **``english-german-both.pkl``** respectively.\n",
        "\n",
        "Download dataset files from here: https://drive.google.com/open?id=1gWVk7SuuE93Cf_nT9Lb7GBCiwfAgdBiX\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x9JDfVgWosMJ"
      },
      "source": [
        "# Character level Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP4P2nnAXD5G",
        "colab_type": "text"
      },
      "source": [
        "## Initialize parameters\n",
        "Run the below code to initialize the variables required for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4jRTxBQ9owHH",
        "colab": {}
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 10  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = 'fra.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0N1Q-zzUJtO0"
      },
      "source": [
        "### Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SEtf-c5Fo7eF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "dceb2df4-14cd-4e33-fd1f-84725146150d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mv0XAJSZJyOl"
      },
      "source": [
        "### Give the path for the folder in which the dataset is present in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fXQOArlSo8SX",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/SequentialRNN/InternalLab10/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoEhVDh3qfuj",
        "colab_type": "text"
      },
      "source": [
        "### Change present working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-plftRTqlgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GkAdNgJrKDvK"
      },
      "source": [
        "## Load the pickle file (`english-german-both.pkl`) into a variable with name `dataset`\n",
        "Run the below code to load the .pkl file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a8fpd1Lxo8VH",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(project_path + 'english-german-both.pkl', 'rb') as f:\n",
        "  dataset = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9pkL351SKaWb"
      },
      "source": [
        "## Check the `dataset` variable at this step. It should be as given below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D6kEL_65KmHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "cc380059-5d47-4b81-ddbc-0507724e3139"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['stay with us', 'bleib bei uns'],\n",
              "       ['she wants him', 'sie will ihn'],\n",
              "       ['youre strong', 'du bist stark'],\n",
              "       ...,\n",
              "       ['i thought so', 'das dachte ich mir'],\n",
              "       ['keep warm', 'haltet euch warm'],\n",
              "       ['im sick', 'ich bin krank']], dtype='<U291')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uQ270GmwK2Qt"
      },
      "source": [
        "## Feature set and target set division from the **dataset**\n",
        "\n",
        "### Run the below code to divide the dataset into feature set(input) and target set(output). \n",
        "\n",
        "1. We are creating two lists for storing input sentences and output sentences separately. \n",
        "2. We are storing each character in a list from both input and target sets separately. \n",
        "3. Print and check `input_texts` and `target_texts`.\n",
        "4. Print and check `input_characters` and `target_characters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fJ95hstto8Xy",
        "colab": {}
      },
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "for line in dataset[: min(num_samples, len(dataset) - 1)]:\n",
        "    input_text, target_text = line[0], line[1]\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwWZMeVjlPjB",
        "colab_type": "text"
      },
      "source": [
        "### Print input text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-1OyZSULuJY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70baad5f-1c62-4dea-eb6b-c2aefd993b01"
      },
      "source": [
        "input_texts"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stay with us',\n",
              " 'she wants him',\n",
              " 'youre strong',\n",
              " 'examine this',\n",
              " 'heres my card',\n",
              " 'tom burped',\n",
              " 'it is no joke',\n",
              " 'tom is a spy',\n",
              " 'im a teenager',\n",
              " 'im not crazy',\n",
              " 'we cant do it',\n",
              " 'i like sweets',\n",
              " 'put it down',\n",
              " 'tom looks fine',\n",
              " 'i am hungarian',\n",
              " 'youre dying',\n",
              " 'go away',\n",
              " 'tom denied this',\n",
              " 'yes of course',\n",
              " 'this is ugly',\n",
              " 'tom cried again',\n",
              " 'ill prove it',\n",
              " 'do as he says',\n",
              " 'please tell me',\n",
              " 'he had ambition',\n",
              " 'look here',\n",
              " 'cuff him',\n",
              " 'is it far away',\n",
              " 'were cousins',\n",
              " 'is tom dreaming',\n",
              " 'i envy tom',\n",
              " 'find a job',\n",
              " 'im the expert',\n",
              " 'just try it',\n",
              " 'theyll find me',\n",
              " 'a car hit tom',\n",
              " 'have tom do it',\n",
              " 'close your eyes',\n",
              " 'come on in here',\n",
              " 'i like this',\n",
              " 'tom is history',\n",
              " 'try it on',\n",
              " 'ill sleep here',\n",
              " 'does that help',\n",
              " 'tom moved away',\n",
              " 'well be ok',\n",
              " 'im on my own',\n",
              " 'toms out cold',\n",
              " 'eat everything',\n",
              " 'you said it',\n",
              " 'he looked young',\n",
              " 'dont insult me',\n",
              " 'im upset',\n",
              " 'you never ask',\n",
              " 'i broke it',\n",
              " 'theyre happy',\n",
              " 'tom seemed sad',\n",
              " 'tom is a loser',\n",
              " 'its up to you',\n",
              " 'are these ours',\n",
              " 'tom cant leave',\n",
              " 'he quit smoking',\n",
              " 'is tom with you',\n",
              " 'tom was hurt',\n",
              " 'ill miss that',\n",
              " 'stay at home',\n",
              " 'everyone smiled',\n",
              " 'im exhausted',\n",
              " 'he saw the girl',\n",
              " 'he has ten cows',\n",
              " 'throw the dice',\n",
              " 'go away',\n",
              " 'who wrote this',\n",
              " 'is tom adopted',\n",
              " 'youre vain',\n",
              " 'i cant help it',\n",
              " 'im in denial',\n",
              " 'now stop crying',\n",
              " 'im not here',\n",
              " 'i hate sand',\n",
              " 'take control',\n",
              " 'tom was upset',\n",
              " 'ill inform tom',\n",
              " 'lets begin',\n",
              " 'try and sing',\n",
              " 'its',\n",
              " 'im sad now',\n",
              " 'im thirty',\n",
              " 'take it to tom',\n",
              " 'toms not in',\n",
              " 'a boat capsized',\n",
              " 'tom cant cook',\n",
              " 'please stop it',\n",
              " 'am i safe here',\n",
              " 'that cost a lot',\n",
              " 'thatd be fine',\n",
              " 'they vanished',\n",
              " 'tom hates rats',\n",
              " 'who succeeded',\n",
              " 'i exaggerated',\n",
              " 'hi',\n",
              " 'i need ice',\n",
              " 'he learns fast',\n",
              " 'wake up tom',\n",
              " 'i feel terrific',\n",
              " 'ive been fired',\n",
              " 'toms sorry',\n",
              " 'youre not tom',\n",
              " 'i am well',\n",
              " 'ill go see',\n",
              " 'dont be sad',\n",
              " 'finish this',\n",
              " 'tom wants more',\n",
              " 'its rush hour',\n",
              " 'are you envious',\n",
              " 'act like a man',\n",
              " 'we all laughed',\n",
              " 'a man must work',\n",
              " 'hand it over',\n",
              " 'hug me',\n",
              " 'tom will shoot',\n",
              " 'tom is family',\n",
              " 'i think so',\n",
              " 'tom had to wait',\n",
              " 'he is delicate',\n",
              " 'tom panicked',\n",
              " 'how about you',\n",
              " 'we had to come',\n",
              " 'is tom good',\n",
              " 'i do love you',\n",
              " 'get off my car',\n",
              " 'i like cartoons',\n",
              " 'the leaves fell',\n",
              " 'im thirty',\n",
              " 'were fasting',\n",
              " 'youre fired',\n",
              " 'hes studying',\n",
              " 'tom is packing',\n",
              " 'give tom a call',\n",
              " 'he had a stroke',\n",
              " 'pigs cant fly',\n",
              " 'thats a relief',\n",
              " 'are you rich',\n",
              " 'he loves trains',\n",
              " 'give it to her',\n",
              " 'ill come down',\n",
              " 'it works',\n",
              " 'what is it now',\n",
              " 'ill attend',\n",
              " 'were reading',\n",
              " 'its very big',\n",
              " 'lend us a hand',\n",
              " 'i deserve more',\n",
              " 'wait a sec',\n",
              " 'i hate working',\n",
              " 'i want you here',\n",
              " 'i like your car',\n",
              " 'he arrived late',\n",
              " 'forget it',\n",
              " 'i went there',\n",
              " 'weve found it',\n",
              " 'youre witty',\n",
              " 'it is raining',\n",
              " 'wait up',\n",
              " 'hes loaded',\n",
              " 'im a man',\n",
              " 'now i feel bad',\n",
              " 'now do you see',\n",
              " 'tom is a cook',\n",
              " 'tom cant ski',\n",
              " 'i came with tom',\n",
              " 'take it down',\n",
              " 'tom intervened',\n",
              " 'i want to win',\n",
              " 'toms adopted',\n",
              " 'ill do my best',\n",
              " 'you should go',\n",
              " 'mary is a widow',\n",
              " 'toms asleep',\n",
              " 'tom didnt talk',\n",
              " 'i rely on tom',\n",
              " 'hows your cold',\n",
              " 'tom cheated me',\n",
              " 'why me',\n",
              " 'stop gossiping',\n",
              " 'dig a deep hole',\n",
              " 'there is hope',\n",
              " 'tom and i ran',\n",
              " 'hoist the sails',\n",
              " 'youre biased',\n",
              " 'tom agreed',\n",
              " 'he was lucky',\n",
              " 'these are mine',\n",
              " 'im not english',\n",
              " 'i must go now',\n",
              " 'i felt lonely',\n",
              " 'heres the key',\n",
              " 'i feel dizzy',\n",
              " 'why is he here',\n",
              " 'hi im tom',\n",
              " 'forgive tom',\n",
              " 'i will help you',\n",
              " 'tom came closer',\n",
              " 'give me those',\n",
              " 'tom is coming',\n",
              " 'they are pretty',\n",
              " 'i cant smoke',\n",
              " 'tom felt uneasy',\n",
              " 'lets see it',\n",
              " 'i like apples',\n",
              " 'dont be crazy',\n",
              " 'tell tom',\n",
              " 'i put my hat on',\n",
              " 'come along',\n",
              " 'im scared',\n",
              " 'lets keep it',\n",
              " 'i need the keys',\n",
              " 'youre paying',\n",
              " 'tom paid me',\n",
              " 'let me try',\n",
              " 'what fun',\n",
              " 'they called',\n",
              " 'i feel so lost',\n",
              " 'get out of bed',\n",
              " 'he lives alone',\n",
              " 'flowers bloom',\n",
              " 'tom went pale',\n",
              " 'im on the list',\n",
              " 'please help me',\n",
              " 'who cares',\n",
              " 'she loves cats',\n",
              " 'im bald',\n",
              " 'toms bored',\n",
              " 'sing us a song',\n",
              " 'hey wait up',\n",
              " 'keep the change',\n",
              " 'i like tom too',\n",
              " 'its new',\n",
              " 'tom is big',\n",
              " 'come alone',\n",
              " 'i forgot it',\n",
              " 'she shot him',\n",
              " 'get down',\n",
              " 'he got very mad',\n",
              " 'youre fired',\n",
              " 'who yelled',\n",
              " 'im not married',\n",
              " 'eat and drink',\n",
              " 'you look great',\n",
              " 'youd love tom',\n",
              " 'tom texted me',\n",
              " 'this is food',\n",
              " 'you look hot',\n",
              " 'i cant see tom',\n",
              " 'lets see it',\n",
              " 'tom took it',\n",
              " 'can you hear it',\n",
              " 'i want proof',\n",
              " 'math is hard',\n",
              " 'were they here',\n",
              " 'toms upset',\n",
              " 'never lose hope',\n",
              " 'tom ignored me',\n",
              " 'tom felt sad',\n",
              " 'toms flaky',\n",
              " 'play it cool',\n",
              " 'im no expert',\n",
              " 'now i know why',\n",
              " 'fill it up',\n",
              " 'im able to run',\n",
              " 'tom ran off',\n",
              " 'tom went crazy',\n",
              " 'ask tom',\n",
              " 'does that count',\n",
              " 'im a salesman',\n",
              " 'theyre broke',\n",
              " 'im making tea',\n",
              " 'tom is average',\n",
              " 'tom loves you',\n",
              " 'im mad at you',\n",
              " 'thats a sign',\n",
              " 'no one likes it',\n",
              " 'jesus loves you',\n",
              " 'get lost',\n",
              " 'please be quiet',\n",
              " 'helium is a gas',\n",
              " 'do men cry',\n",
              " 'he is japanese',\n",
              " 'he is very sick',\n",
              " 'the wind howled',\n",
              " 'try these on',\n",
              " 'dont hurt her',\n",
              " 'tom seems calm',\n",
              " 'call the doctor',\n",
              " 'open this door',\n",
              " 'i am very tired',\n",
              " 'she kicked him',\n",
              " 'tom cant sing',\n",
              " 'ill page tom',\n",
              " 'im toms aunt',\n",
              " 'hug tom',\n",
              " 'do you love me',\n",
              " 'please sit down',\n",
              " 'lets try it',\n",
              " 'tom is blind',\n",
              " 'why is it dark',\n",
              " 'ill miss that',\n",
              " 'i want them all',\n",
              " 'it didnt work',\n",
              " 'we knew enough',\n",
              " 'she stabbed him',\n",
              " 'is this for me',\n",
              " 'look at these',\n",
              " 'can you help us',\n",
              " 'they won',\n",
              " 'i dont like it',\n",
              " 'its accurate',\n",
              " 'i was new',\n",
              " 'well walk',\n",
              " 'read this first',\n",
              " 'tom is ok',\n",
              " 'i like you too',\n",
              " 'tom talks fast',\n",
              " 'well miss you',\n",
              " 'he was standing',\n",
              " 'lets rest here',\n",
              " 'tom cheated',\n",
              " 'you missed',\n",
              " 'i had no clue',\n",
              " 'she is powerful',\n",
              " 'do you want him',\n",
              " 'im healthy',\n",
              " 'they know me',\n",
              " 'im not busy',\n",
              " 'do what i say',\n",
              " 'i like this one',\n",
              " 'nobody saw me',\n",
              " 'i need a doctor',\n",
              " 'tom seems sick',\n",
              " 'she has a cold',\n",
              " 'i like that tie',\n",
              " 'he is poor',\n",
              " 'tom is healthy',\n",
              " 'tom is playing',\n",
              " 'women hate tom',\n",
              " 'tom got better',\n",
              " 'ok i agree',\n",
              " 'its yen',\n",
              " 'theres no gold',\n",
              " 'im optimistic',\n",
              " 'i ran to school',\n",
              " 'wake up',\n",
              " 'tom blinked',\n",
              " 'tom is humming',\n",
              " 'watch this',\n",
              " 'tom didnt stir',\n",
              " 'thats nonsense',\n",
              " 'is that a wig',\n",
              " 'i feel stupid',\n",
              " 'i love monday',\n",
              " 'tom felt hungry',\n",
              " 'leave tomorrow',\n",
              " 'tom owns a car',\n",
              " 'take a walk',\n",
              " 'that was great',\n",
              " 'tom got caught',\n",
              " 'just try it',\n",
              " 'its bulky',\n",
              " 'she lied',\n",
              " 'i wasnt asleep',\n",
              " 'tom is focused',\n",
              " 'tom exhaled',\n",
              " 'hes too old',\n",
              " 'youre here',\n",
              " 'dont break it',\n",
              " 'ive missed you',\n",
              " 'tom is through',\n",
              " 'shes dieting',\n",
              " 'which is mine',\n",
              " 'everyone dreams',\n",
              " 'tom came by',\n",
              " 'tom squinted',\n",
              " 'dont run here',\n",
              " 'i saw somebody',\n",
              " 'i need tom now',\n",
              " 'here i am',\n",
              " 'have a nice day',\n",
              " 'tom cheated',\n",
              " 'dont cry',\n",
              " 'are you hurt',\n",
              " 'she loves cake',\n",
              " 'tom has a limp',\n",
              " 'i am baffled',\n",
              " 'it may snow',\n",
              " 'keep the secret',\n",
              " 'who stayed',\n",
              " 'tom blacked out',\n",
              " 'i need a favor',\n",
              " 'ill enjoy this',\n",
              " 'take mine',\n",
              " 'tom looks well',\n",
              " 'ill allow this',\n",
              " 'i can go',\n",
              " 'leave me alone',\n",
              " 'she came',\n",
              " 'i want to come',\n",
              " 'how about',\n",
              " 'how wide is it',\n",
              " 'id like a book',\n",
              " 'owls are cute',\n",
              " 'take it easy',\n",
              " 'he was naive',\n",
              " 'its two pounds',\n",
              " 'well start',\n",
              " 'tom had a beer',\n",
              " 'its perfect',\n",
              " 'did you vote',\n",
              " 'its up to me',\n",
              " 'hide the money',\n",
              " 'toms sick',\n",
              " 'whats tom do',\n",
              " 'do we have one',\n",
              " 'we all lie',\n",
              " 'is tom ill',\n",
              " 'she sings well',\n",
              " 'i bit my tongue',\n",
              " 'this is my cat',\n",
              " 'its your fault',\n",
              " 'show me',\n",
              " 'i dont see why',\n",
              " 'i wont be long',\n",
              " 'do it yourself',\n",
              " 'toms wrong',\n",
              " 'im a prisoner',\n",
              " 'there it is',\n",
              " 'i see that',\n",
              " 'tom improvised',\n",
              " 'im a night owl',\n",
              " 'leave us alone',\n",
              " 'tom obeyed',\n",
              " 'this annoys me',\n",
              " 'i need internet',\n",
              " 'hes very ill',\n",
              " 'well lets go',\n",
              " 'we know tom',\n",
              " 'he is my father',\n",
              " 'pandas are cute',\n",
              " 'heres',\n",
              " 'nobody came',\n",
              " 'im going too',\n",
              " 'im not ready',\n",
              " 'im having fun',\n",
              " 'is it foggy',\n",
              " 'there was music',\n",
              " 'it works great',\n",
              " 'is your car new',\n",
              " 'whats on tv',\n",
              " 'i said stop it',\n",
              " 'she is a beauty',\n",
              " 'tom was mugged',\n",
              " 'good night',\n",
              " 'dont touch me',\n",
              " 'tom got cheated',\n",
              " 'calm down',\n",
              " 'ill look it up',\n",
              " 'i need friends',\n",
              " 'he made me go',\n",
              " 'it had snowed',\n",
              " 'tom knew',\n",
              " 'talk to me',\n",
              " 'just go away',\n",
              " 'do we have time',\n",
              " 'lets get drunk',\n",
              " 'stop',\n",
              " 'hes austrian',\n",
              " 'can it be true',\n",
              " 'isnt it great',\n",
              " 'thats a risk',\n",
              " 'how deep',\n",
              " 'she hated him',\n",
              " 'it burned',\n",
              " 'that isnt it',\n",
              " 'tom seemed mad',\n",
              " 'who died',\n",
              " 'tom fought well',\n",
              " 'dont be upset',\n",
              " 'its too hard',\n",
              " 'dont lose hope',\n",
              " 'i burp a lot',\n",
              " 'it just bugs me',\n",
              " 'its too risky',\n",
              " 'tom is lazy',\n",
              " 'he is eating',\n",
              " 'tom dozed',\n",
              " 'everyone agreed',\n",
              " 'lets ditch tom',\n",
              " 'its all right',\n",
              " 'tom was humble',\n",
              " 'hug me',\n",
              " 'i loved school',\n",
              " 'goodbye',\n",
              " 'hes innocent',\n",
              " 'do you want any',\n",
              " 'im a redhead',\n",
              " 'tom saw her',\n",
              " 'even tom lied',\n",
              " 'tom smelled it',\n",
              " 'i say go for it',\n",
              " 'i read a lot',\n",
              " 'its so simple',\n",
              " 'they canceled',\n",
              " 'come sit by me',\n",
              " 'can i ask why',\n",
              " 'tom hates cats',\n",
              " 'black suits you',\n",
              " 'take it easy',\n",
              " 'is it not black',\n",
              " 'is it a weapon',\n",
              " 'i wasnt alone',\n",
              " 'read this book',\n",
              " 'come with me',\n",
              " 'just let tom go',\n",
              " 'are you fair',\n",
              " 'well stand',\n",
              " 'ill be nice',\n",
              " 'who quit',\n",
              " 'use your charm',\n",
              " 'i love him',\n",
              " 'this is the boy',\n",
              " 'try this sauce',\n",
              " 'kiss me',\n",
              " 'its yours',\n",
              " 'shut the book',\n",
              " 'tom can answer',\n",
              " 'tom felt woozy',\n",
              " 'i meant no harm',\n",
              " 'he just arrived',\n",
              " 'look closely',\n",
              " 'can i leave now',\n",
              " 'tom was unfair',\n",
              " 'brace yourself',\n",
              " 'tom almost died',\n",
              " 'thats not fair',\n",
              " 'he is asleep',\n",
              " 'tom protested',\n",
              " 'why is it here',\n",
              " 'i loved her',\n",
              " 'did you make it',\n",
              " 'can we come',\n",
              " 'guess who i am',\n",
              " 'the cup broke',\n",
              " 'no one knew why',\n",
              " 'was it good',\n",
              " 'he coughed',\n",
              " 'this is for you',\n",
              " 'tom isnt mean',\n",
              " 'take a walk',\n",
              " 'we got married',\n",
              " 'youd like tom',\n",
              " 'we want a car',\n",
              " 'im jealous',\n",
              " 'dont be rude',\n",
              " 'she was crying',\n",
              " 'sharks eat fish',\n",
              " 'dont play here',\n",
              " 'im very hungry',\n",
              " 'he seems hungry',\n",
              " 'ive been shot',\n",
              " 'take cover',\n",
              " 'im no quitter',\n",
              " 'do you know me',\n",
              " 'are you serious',\n",
              " 'who says that',\n",
              " 'he was at home',\n",
              " 'tom is a dwarf',\n",
              " 'they fell',\n",
              " 'talk to tom',\n",
              " 'im coming home',\n",
              " 'tom came by car',\n",
              " 'im happy too',\n",
              " 'tom is willing',\n",
              " 'he drank a beer',\n",
              " 'tell tom',\n",
              " 'i love harvard',\n",
              " 'tom got killed',\n",
              " 'i envy her',\n",
              " 'youre joking',\n",
              " 'theyre quiet',\n",
              " 'i see the book',\n",
              " 'are you busy',\n",
              " 'it would be fun',\n",
              " 'i see a giraffe',\n",
              " 'tomll come',\n",
              " 'we shook hands',\n",
              " 'am i qualified',\n",
              " 'you better go',\n",
              " 'can you help',\n",
              " 'merry christmas',\n",
              " 'tom was tired',\n",
              " 'did you sign',\n",
              " 'do you eat meat',\n",
              " 'hes an author',\n",
              " 'is he all right',\n",
              " 'is tom working',\n",
              " 'give tom a call',\n",
              " 'he is kind',\n",
              " 'thats stupid',\n",
              " 'keep me updated',\n",
              " 'get lost',\n",
              " 'dont go yet',\n",
              " 'get lost',\n",
              " 'come home',\n",
              " 'is he at home',\n",
              " 'youre humming',\n",
              " 'he is american',\n",
              " 'today is monday',\n",
              " 'hes coming',\n",
              " 'watch us',\n",
              " 'his word is law',\n",
              " 'get off me',\n",
              " 'get on in here',\n",
              " 'hes not ready',\n",
              " 'give it to me',\n",
              " 'i wont come',\n",
              " 'i was invited',\n",
              " 'look ahead',\n",
              " 'who ate',\n",
              " 'im tom jackson',\n",
              " 'i fear nothing',\n",
              " 'you have mail',\n",
              " 'he is old',\n",
              " 'we didnt try',\n",
              " 'i want this one',\n",
              " 'ask tom again',\n",
              " 'that man is tom',\n",
              " 'my work is done',\n",
              " 'she got up late',\n",
              " 'i like it hot',\n",
              " 'toms filthy',\n",
              " 'life is crazy',\n",
              " 'this is a pen',\n",
              " 'im a nurse',\n",
              " 'youre sick',\n",
              " 'youre silly',\n",
              " 'i promise',\n",
              " 'im quite busy',\n",
              " 'we need tools',\n",
              " 'be realistic',\n",
              " 'send it to me',\n",
              " 'i misjudged tom',\n",
              " 'im hiding',\n",
              " 'who fell',\n",
              " 'im not evil',\n",
              " 'cool off',\n",
              " 'im often here',\n",
              " 'i want mary',\n",
              " 'im eating',\n",
              " 'tom betrayed us',\n",
              " 'let tom answer',\n",
              " 'i borrow money',\n",
              " 'i must go there',\n",
              " 'tom had a cat',\n",
              " 'i know her',\n",
              " 'tom was sweet',\n",
              " 'toms sad',\n",
              " 'are you married',\n",
              " 'tom cant work',\n",
              " 'youre unusual',\n",
              " 'ignore tom',\n",
              " 'i want to leave',\n",
              " 'just check it',\n",
              " 'this is my home',\n",
              " 'how are you',\n",
              " 'i said take it',\n",
              " 'get out',\n",
              " 'give me a hand',\n",
              " 'ill live',\n",
              " 'ask me tomorrow',\n",
              " 'open your mouth',\n",
              " 'is it in there',\n",
              " 'i saw to it',\n",
              " 'it sounds great',\n",
              " 'ill pay later',\n",
              " 'who did it',\n",
              " 'what about you',\n",
              " 'ill be fine',\n",
              " 'i woke you up',\n",
              " 'do you love me',\n",
              " 'my hip hurts',\n",
              " 'they had a boat',\n",
              " 'i lost my key',\n",
              " 'i won',\n",
              " 'i looked down',\n",
              " 'they understood',\n",
              " 'she stood up',\n",
              " 'are you sisters',\n",
              " 'toms scared',\n",
              " 'tom doesnt lie',\n",
              " 'toms so old',\n",
              " 'im miserable',\n",
              " 'youre dying',\n",
              " 'toms innocent',\n",
              " 'stop dreaming',\n",
              " 'i forgave tom',\n",
              " 'did you say yes',\n",
              " 'i eat fruit',\n",
              " 'i paid my bills',\n",
              " 'go away',\n",
              " 'tom smokes',\n",
              " 'fire',\n",
              " 'even tom smiled',\n",
              " 'are you crazy',\n",
              " 'he is ethiopian',\n",
              " 'go away',\n",
              " 'i must be blind',\n",
              " 'we need help',\n",
              " 'she worked hard',\n",
              " 'tom spoke',\n",
              " 'theyre crazy',\n",
              " 'well ask tom',\n",
              " 'im very afraid',\n",
              " 'i felt isolated',\n",
              " 'i was upset',\n",
              " 'i thought so',\n",
              " 'can i join in',\n",
              " 'lets try',\n",
              " 'i was too shy',\n",
              " 'look in there',\n",
              " 'turn up the tv',\n",
              " 'give me the key',\n",
              " 'is it my turn',\n",
              " 'i was ready',\n",
              " 'is it tasty',\n",
              " 'you stink',\n",
              " 'im hiding',\n",
              " 'tom loves you',\n",
              " 'i had doubts',\n",
              " 'i lost a bet',\n",
              " 'put on a robe',\n",
              " 'open this door',\n",
              " 'it is necessary',\n",
              " 'keep tom there',\n",
              " 'she pinched him',\n",
              " 'was tom there',\n",
              " 'get away',\n",
              " 'ill follow tom',\n",
              " 'i saw that',\n",
              " 'she adores cats',\n",
              " 'anybody will do',\n",
              " 'i want one',\n",
              " 'i enjoy reading',\n",
              " 'tom can help us',\n",
              " 'get away',\n",
              " 'please stop it',\n",
              " 'i saw them',\n",
              " 'i resigned',\n",
              " 'tom objected',\n",
              " 'there she comes',\n",
              " 'trust in god',\n",
              " 'shame on you',\n",
              " 'he was stoned',\n",
              " 'no problem',\n",
              " 'im addicted',\n",
              " 'tom cheated',\n",
              " 'let tom do it',\n",
              " 'tom took risks',\n",
              " 'i made these',\n",
              " 'well go out',\n",
              " 'why quit now',\n",
              " 'i like your car',\n",
              " 'tom was skiing',\n",
              " 'whats in here',\n",
              " 'i must buy one',\n",
              " 'i want more',\n",
              " 'watch us',\n",
              " 'tom squinted',\n",
              " 'shes busy',\n",
              " 'look there',\n",
              " 'you may go',\n",
              " 'try to guess',\n",
              " 'theyre enemies',\n",
              " 'count me in',\n",
              " 'tom is gasping',\n",
              " 'go away',\n",
              " 'its locked',\n",
              " 'let tom speak',\n",
              " 'i feel strong',\n",
              " 'i teach french',\n",
              " 'tom has guts',\n",
              " 'im a cook',\n",
              " 'he was perfect',\n",
              " 'quiet down',\n",
              " 'get lost',\n",
              " 'youll get one',\n",
              " 'have him come',\n",
              " 'tom can get it',\n",
              " 'call the fbi',\n",
              " 'got it',\n",
              " 'are you excited',\n",
              " 'who ran',\n",
              " 'lets go',\n",
              " 'she cant swim',\n",
              " 'its a surprise',\n",
              " 'lets go by bus',\n",
              " 'i read the book',\n",
              " 'i can run',\n",
              " 'no one told me',\n",
              " 'i love my home',\n",
              " 'my wife is mad',\n",
              " 'i assume so',\n",
              " 'well see',\n",
              " 'im sure',\n",
              " 'its hot today',\n",
              " 'dont mind me',\n",
              " 'i am busy today',\n",
              " 'tom is a fool',\n",
              " 'is she japanese',\n",
              " 'tom smells bad',\n",
              " 'we love coffee',\n",
              " 'i am a cook',\n",
              " 'who wants tea',\n",
              " 'you never know',\n",
              " 'well be there',\n",
              " 'boys are stupid',\n",
              " 'what do i need',\n",
              " 'thats not nice',\n",
              " 'im replaceable',\n",
              " 'is tom serious',\n",
              " 'this is tom',\n",
              " 'stay cool',\n",
              " 'i wear glasses',\n",
              " 'isnt that ours',\n",
              " 'bring it to me',\n",
              " 'i love my ipod',\n",
              " 'he almost died',\n",
              " 'they are pilots',\n",
              " 'i dont get you',\n",
              " 'she might come',\n",
              " 'im in perth',\n",
              " 'toms up',\n",
              " 'can i help you',\n",
              " 'tom is down',\n",
              " 'this is tom',\n",
              " 'thats my car',\n",
              " 'i recommend tom',\n",
              " 'stay for supper',\n",
              " 'my eyes hurt',\n",
              " 'boil one egg',\n",
              " 'im a bit tired',\n",
              " 'i want a book',\n",
              " 'you were brave',\n",
              " 'come forward',\n",
              " 'i dont need it',\n",
              " 'take everything',\n",
              " 'he hung up',\n",
              " 'i miss it',\n",
              " 'tom read a lot',\n",
              " 'thatll be fun',\n",
              " 'go away',\n",
              " 'we were busy',\n",
              " 'give them to me',\n",
              " 'wholl cook',\n",
              " 'count me in',\n",
              " 'tom shot mary',\n",
              " 'send it to me',\n",
              " 'i dont see it',\n",
              " 'who is next',\n",
              " 'who is absent',\n",
              " 'tom frowned',\n",
              " 'is it yours',\n",
              " 'go that way',\n",
              " 'im in here',\n",
              " 'tom stood back',\n",
              " 'are you honest',\n",
              " 'jump over it',\n",
              " 'this is my bag',\n",
              " 'this is great',\n",
              " 'dont wait',\n",
              " 'i went to paris',\n",
              " 'is this wine',\n",
              " 'watch closely',\n",
              " 'let tom do this',\n",
              " 'i want this',\n",
              " 'this is life',\n",
              " 'you were happy',\n",
              " 'i hate mondays',\n",
              " 'i ran home',\n",
              " 'tom was mad',\n",
              " 'seals eat fish',\n",
              " 'vote for me',\n",
              " 'tom is old',\n",
              " 'did tom notice',\n",
              " 'im thirsty',\n",
              " 'were armed',\n",
              " 'well call you',\n",
              " 'were starving',\n",
              " 'were fighting',\n",
              " 'thats right',\n",
              " 'thats sad',\n",
              " 'i am ready',\n",
              " 'let me do it',\n",
              " 'tom is loud',\n",
              " 'beat it',\n",
              " 'dont freak out',\n",
              " 'we were right',\n",
              " 'speak slower',\n",
              " 'tom is pleased',\n",
              " 'lets call tom',\n",
              " 'tom has it',\n",
              " 'heres the plan',\n",
              " 'youve done it',\n",
              " 'look at that',\n",
              " 'thats a tower',\n",
              " 'mary is weird',\n",
              " 'youre so lazy',\n",
              " 'isnt it true',\n",
              " 'she avoids me',\n",
              " 'tom was honest',\n",
              " 'its a fad',\n",
              " 'can i bring tom',\n",
              " 'thats a copy',\n",
              " 'trust me',\n",
              " 'its no use',\n",
              " 'keep away',\n",
              " 'i have no horse',\n",
              " 'let me in',\n",
              " 'im still young',\n",
              " 'does he know me',\n",
              " 'i hate politics',\n",
              " 'loosen it',\n",
              " 'i love her',\n",
              " 'i am a shy boy',\n",
              " 'i called him up',\n",
              " 'tom loved it',\n",
              " 'give me a kiss',\n",
              " 'where is mary',\n",
              " 'well stop tom',\n",
              " 'how weird',\n",
              " 'come along',\n",
              " 'youre a loser',\n",
              " 'kids need sleep',\n",
              " 'i was furious',\n",
              " 'she led me on',\n",
              " 'did you see it',\n",
              " 'im never wrong',\n",
              " 'lets get a cab',\n",
              " 'did tom say why',\n",
              " 'that is her car',\n",
              " 'tom died there',\n",
              " 'we do love it',\n",
              " 'its useless',\n",
              " 'i teach chinese',\n",
              " 'i want to learn',\n",
              " 'i often hiccup',\n",
              " 'nobody was home',\n",
              " 'i am busy now',\n",
              " 'dont mind me',\n",
              " 'let me leave',\n",
              " 'you need help',\n",
              " 'pull over here',\n",
              " 'her father died',\n",
              " 'dont do it',\n",
              " 'i became angry',\n",
              " 'hold on to it',\n",
              " 'catch tom',\n",
              " 'hold this',\n",
              " 'im on the roof',\n",
              " 'tom blames us',\n",
              " 'i just found it',\n",
              " 'this will pass',\n",
              " 'whos at fault',\n",
              " 'he is not young',\n",
              " 'tom got excited',\n",
              " 'memorize it',\n",
              " 'youre welcome',\n",
              " 'i volunteered',\n",
              " 'isnt tom cool',\n",
              " 'lock it',\n",
              " 'i was a witness',\n",
              " 'the girls won',\n",
              " 'he mentioned it',\n",
              " 'tom had a gun',\n",
              " 'i love you tom',\n",
              " 'throw it there',\n",
              " 'theyre broken',\n",
              " 'i missed you',\n",
              " 'look here',\n",
              " 'lets start',\n",
              " 'he has come',\n",
              " 'i have failed',\n",
              " 'no one knows',\n",
              " 'well find tom',\n",
              " 'lets find tom',\n",
              " 'were paying',\n",
              " 'youre jealous',\n",
              " 'tom is in pain',\n",
              " 'i think so too',\n",
              " 'i study french',\n",
              " 'who cheated',\n",
              " 'i like my job',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo7Mno1JlVWP",
        "colab_type": "text"
      },
      "source": [
        "### Print target text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_pnLXkk8LzBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b2a391e9-ecf2-46ef-c0c6-a51f9f9d79cd"
      },
      "source": [
        "print(target_text)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\thaltet euch warm\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7IhmN_hlb1K",
        "colab_type": "text"
      },
      "source": [
        "### Print input character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9az5VYFjNe7I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b9c93d4-8c4d-4524-d8e8-80b2f99f9406"
      },
      "source": [
        "print(input_characters)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'e', 'p', 'u', 'm', 'o', 'x', 's', 't', 'b', 'k', 'l', 'y', 'q', 'z', 'n', 'i', 'g', 'v', ' ', 'd', 'w', 'a', 'f', 'h', 'c', 'r', 'j'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX30Y8dZlfGQ",
        "colab_type": "text"
      },
      "source": [
        "### Print target character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kxg3509lNjnU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08b62f44-4c94-4010-e06a-f6d1c5f73eb9"
      },
      "source": [
        "print(target_characters)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'e', '\\n', 'p', 'u', 'm', 'o', 'x', 's', 't', 'b', 'k', 'l', 'y', 'q', 'z', 'n', 'i', 'g', 'v', ' ', 'd', 'w', 'a', 'f', '\\t', 'h', 'c', 'r', 'j'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dw10uDT3Oc1N"
      },
      "source": [
        "## Stats from the dataset\n",
        "\n",
        "### Run the below code to check the stats from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T4stnzMpo8ci",
        "colab": {}
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VfbreAAUo8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "67704042-f5aa-413e-8f3c-07b5dd0fec5b"
      },
      "source": [
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 9999\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 29\n",
            "Max sequence length for inputs: 15\n",
            "Max sequence length for outputs: 51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mVuwMY0UTVKD"
      },
      "source": [
        "## Build character to index dictionary names `input_token_index` and `target_token_index` for input and target sets respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QYXSW9zOo8hl",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo-HQbNq6mna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8b8ed1e-cc64-4b85-d3cb-8b82f2b89b1c"
      },
      "source": [
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aUS5gEamGiC",
        "colab_type": "text"
      },
      "source": [
        "### Print input_index_token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "__ga4KfKTijk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "228b34e2-29cf-4183-eb15-536161c7b067"
      },
      "source": [
        "input_token_index"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'a': 1,\n",
              " 'b': 2,\n",
              " 'c': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'f': 6,\n",
              " 'g': 7,\n",
              " 'h': 8,\n",
              " 'i': 9,\n",
              " 'j': 10,\n",
              " 'k': 11,\n",
              " 'l': 12,\n",
              " 'm': 13,\n",
              " 'n': 14,\n",
              " 'o': 15,\n",
              " 'p': 16,\n",
              " 'q': 17,\n",
              " 'r': 18,\n",
              " 's': 19,\n",
              " 't': 20,\n",
              " 'u': 21,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 24,\n",
              " 'y': 25,\n",
              " 'z': 26}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGs66ZhjmNBA",
        "colab_type": "text"
      },
      "source": [
        "### Print target_token_index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sa3DArDrTm1z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "a73adc48-f287-42a6-c3c5-6bde2ec5f42f"
      },
      "source": [
        "target_token_index"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\t': 0,\n",
              " '\\n': 1,\n",
              " ' ': 2,\n",
              " 'a': 3,\n",
              " 'b': 4,\n",
              " 'c': 5,\n",
              " 'd': 6,\n",
              " 'e': 7,\n",
              " 'f': 8,\n",
              " 'g': 9,\n",
              " 'h': 10,\n",
              " 'i': 11,\n",
              " 'j': 12,\n",
              " 'k': 13,\n",
              " 'l': 14,\n",
              " 'm': 15,\n",
              " 'n': 16,\n",
              " 'o': 17,\n",
              " 'p': 18,\n",
              " 'q': 19,\n",
              " 'r': 20,\n",
              " 's': 21,\n",
              " 't': 22,\n",
              " 'u': 23,\n",
              " 'v': 24,\n",
              " 'w': 25,\n",
              " 'x': 26,\n",
              " 'y': 27,\n",
              " 'z': 28}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8zfLmrc7I48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG1cMyqg7KpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "56655bef-db88-4b6c-d546-4dcdbd255a56"
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0811 09:07:03.616192 140314871314304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0811 09:07:03.659262 140314871314304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0811 09:07:03.668730 140314871314304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlgzM07Y7qlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UB7uI724TrlM"
      },
      "source": [
        "## Build Model\n",
        "Initialize the required layers from keras\n",
        "\n",
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T1GuGnDiqOz3",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3q9GVu-pT9UR"
      },
      "source": [
        "### Run the below code to build one-hot vectors for the characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uatzEBy5qIpI",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MDGoIZXuqLF7",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i0ihyyfeW7le"
      },
      "source": [
        "### Build the encoder Model\n",
        "\n",
        "Define an input sequence and process it.\n",
        "\n",
        "Discard `encoder_outputs` and only keep the states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CQU4zjxdqXnG",
        "colab": {}
      },
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X3PzX5oBXfGW"
      },
      "source": [
        "### Build the decoder Model\n",
        "\n",
        "Set up the decoder, using `encoder_states` as initial state.\n",
        "\n",
        "We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ytn5MNCjqZuc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76850ab2-0ee9-4f18-e34d-6f37bd2a605e"
      },
      "source": [
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=30,\n",
        "          validation_split=0.2)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0811 09:08:28.347861 140314871314304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0811 09:08:28.370360 140314871314304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0811 09:08:28.505913 140314871314304 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0811 09:08:29.661999 140314871314304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 7999 samples, validate on 2000 samples\n",
            "Epoch 1/30\n",
            "7999/7999 [==============================] - 15s 2ms/step - loss: 0.9572 - val_loss: 0.8162\n",
            "Epoch 2/30\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.7478 - val_loss: 0.6771\n",
            "Epoch 3/30\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.6447 - val_loss: 0.6014\n",
            "Epoch 4/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.5872 - val_loss: 0.5591\n",
            "Epoch 5/30\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.5501 - val_loss: 0.5324\n",
            "Epoch 6/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.5211 - val_loss: 0.5049\n",
            "Epoch 7/30\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.4975 - val_loss: 0.4899\n",
            "Epoch 8/30\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.4768 - val_loss: 0.4740\n",
            "Epoch 9/30\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.4585 - val_loss: 0.4591\n",
            "Epoch 10/30\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.4418 - val_loss: 0.4473\n",
            "Epoch 11/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.4264 - val_loss: 0.4371\n",
            "Epoch 12/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.4127 - val_loss: 0.4268\n",
            "Epoch 13/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3988 - val_loss: 0.4201\n",
            "Epoch 14/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3867 - val_loss: 0.4141\n",
            "Epoch 15/30\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.3745 - val_loss: 0.4101\n",
            "Epoch 16/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3634 - val_loss: 0.4014\n",
            "Epoch 17/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3523 - val_loss: 0.3953\n",
            "Epoch 18/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3422 - val_loss: 0.3930\n",
            "Epoch 19/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3324 - val_loss: 0.3869\n",
            "Epoch 20/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3224 - val_loss: 0.3852\n",
            "Epoch 21/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3135 - val_loss: 0.3837\n",
            "Epoch 22/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3048 - val_loss: 0.3804\n",
            "Epoch 23/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2960 - val_loss: 0.3795\n",
            "Epoch 24/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2880 - val_loss: 0.3771\n",
            "Epoch 25/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2800 - val_loss: 0.3771\n",
            "Epoch 26/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2723 - val_loss: 0.3781\n",
            "Epoch 27/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2650 - val_loss: 0.3759\n",
            "Epoch 28/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2578 - val_loss: 0.3759\n",
            "Epoch 29/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2510 - val_loss: 0.3759\n",
            "Epoch 30/30\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2439 - val_loss: 0.3802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpJnlQgvn8vN",
        "colab_type": "text"
      },
      "source": [
        "### Define Model\n",
        "\n",
        "Define the model that will turn `encoder_input_data ` & ` decoder_input_data` into `decoder_target_data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E24IW9wIqcYq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qvawc6CfXkzG"
      },
      "source": [
        "### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhXLFmApqeU4",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o4khltlof6H",
        "colab_type": "text"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVgGMc5Lojmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e6db7e43-4481-481f-8587-1cac35cb4c30"
      },
      "source": [
        "# Save model\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zbLdraJ1XpsR"
      },
      "source": [
        "## Run the below code for inferencing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4O7jtJYh29uo",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scaoVQVapHLk",
        "colab_type": "text"
      },
      "source": [
        "## Reverse-lookup token index to decode sequences back to something readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_3t_ntoTq0fP",
        "colab": {}
      },
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9WAWX6ApcrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "db887d05-4bd1-47a9-c800-da643e07b40d"
      },
      "source": [
        "print(reverse_input_char_index)\n",
        "print(reverse_target_char_index)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: ' ', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
            "{0: '\\t', 1: '\\n', 2: ' ', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FYJkd_AZq0iI",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jiPl9MHkXv0z"
      },
      "source": [
        "## Run the below code for checking some outputs from the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7IFQIeCGq0nk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "7acf0049-4d8f-4c5b-e6ed-c240eb4bdf0b"
      },
      "source": [
        "for seq_index in range(10):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: stay with us\n",
            "Decoded sentence: bleib da unt\n",
            "\n",
            "-\n",
            "Input sentence: she wants him\n",
            "Decoded sentence: sie hat ihn gekossen\n",
            "\n",
            "-\n",
            "Input sentence: youre strong\n",
            "Decoded sentence: du bist so faul\n",
            "\n",
            "-\n",
            "Input sentence: examine this\n",
            "Decoded sentence: scher dich bott\n",
            "\n",
            "-\n",
            "Input sentence: heres my card\n",
            "Decoded sentence: hier ist der schlussel\n",
            "\n",
            "-\n",
            "Input sentence: tom burped\n",
            "Decoded sentence: tom hat mich geschnitten\n",
            "\n",
            "-\n",
            "Input sentence: it is no joke\n",
            "Decoded sentence: es ist ein geweinn\n",
            "\n",
            "-\n",
            "Input sentence: tom is a spy\n",
            "Decoded sentence: tom ist schwach\n",
            "\n",
            "-\n",
            "Input sentence: im a teenager\n",
            "Decoded sentence: ich bin sehr gestorben\n",
            "\n",
            "-\n",
            "Input sentence: im not crazy\n",
            "Decoded sentence: ich bin nicht beschaftigt\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D43ZzyGJ9dkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}